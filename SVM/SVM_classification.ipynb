{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 엑셀파일로 준비된 데이터를 이용해서 support vector machine을 시험해 봅니다. \n",
    "엑셀파일에서 데이터는 예제 xlsx파일을 참고하여 첫 번째 세로줄이 label, 두 번째 세로줄부터 feature가 되도록 준비하면 됩니다. label은 0,1,2,3, ... 의 숫자로 준비하는 것이 좋습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (randomly splited training/test sets)\n",
    "여기서는 하나의 엑셀파일에 모든 데이터를 넣고, 랜덤하게 80%의 training set과 20%의 test set으로 나누었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data0 = pandas.read_excel('breastcancer.xlsx')\n",
    "y_vals = data0.values[:,0]\n",
    "x_vals = data0.values[:,1:]\n",
    "train_indices = np.random.choice(len(x_vals),round(len(x_vals)*0.8), replace = False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (defined training/test sets)\n",
    "랜덤하게 데이터를 나누기 보다 미리 정의된 training set과 test set을 사용하고 싶은 경우도 많을 것입니다. 이런 경우에는 각각의 엑셀파일을 준비하셔서 아래의 코드를 사용하시면 됩니다.만약, 미리 엑셀로 준비된 train set과 test set을 사용하고 싶은 경우 위에 있는 코드 대신 아래의 코드를 사용하시면 됩니다. 파일이름은 본인의 파일에 맞게 바꾸어 주셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data0 = pandas.read_excel('breastcancer_train.xlsx')\n",
    "y_vals_train = data0.values[:,0]\n",
    "x_vals_train = data0.values[:,1:]\n",
    "data1 = pandas.read_excel('breastcancer_test.xlsx')\n",
    "y_vals_test = data1.values[:,0]\n",
    "x_vals_test = data1.values[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_vals_train, y_vals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 1.000\n",
      "accuracy on test set: 0.486\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set: {:.3f}\".format(svc.score(x_vals_train, y_vals_train)))\n",
    "print(\"accuracy on test set: {:.3f}\".format(svc.score(x_vals_test, y_vals_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_train = x_vals_train.min(axis=0)\n",
    "range_train = (x_vals_train - min_train).max(axis=0)\n",
    "x_vals_train_scaled = (x_vals_train - min_train)/range_train\n",
    "x_vals_test_scaled = (x_vals_test - min_train)/range_train\n",
    "svc.fit(x_vals_train_scaled, y_vals_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 0.954\n",
      "accuracy on test set: 0.917\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set: {:.3f}\".format(svc.score(x_vals_train_scaled, y_vals_train)))\n",
    "print(\"accuracy on test set: {:.3f}\".format(svc.score(x_vals_test_scaled, y_vals_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=100, gamma=10)\n",
    "svc.fit(x_vals_train_scaled, y_vals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set: 1.000\n",
      "accuracy on test set: 0.972\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set: {:.3f}\".format(svc.score(x_vals_train_scaled, y_vals_train)))\n",
    "print(\"accuracy on test set: {:.3f}\".format(svc.score(x_vals_test_scaled, y_vals_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data no. 1, actual 1, predicted 1\n",
      "data no. 2, actual 1, predicted 1\n",
      "data no. 3, actual 1, predicted 1\n",
      "data no. 4, actual 1, predicted 1\n",
      "data no. 5, actual 1, predicted 1\n",
      "data no. 6, actual 1, predicted 1\n",
      "data no. 7, actual 1, predicted 1\n",
      "data no. 8, actual 1, predicted 1\n",
      "data no. 9, actual 1, predicted 1\n",
      "data no. 10, actual 1, predicted 1\n",
      "data no. 11, actual 1, predicted 1\n",
      "data no. 12, actual 1, predicted 1\n",
      "data no. 13, actual 1, predicted 1\n",
      "data no. 14, actual 0, predicted 0\n",
      "data no. 15, actual 0, predicted 0\n",
      "data no. 16, actual 0, predicted 0\n",
      "data no. 17, actual 0, predicted 0\n",
      "data no. 18, actual 0, predicted 0\n",
      "data no. 19, actual 0, predicted 0\n",
      "data no. 20, actual 1, predicted 1\n",
      "data no. 21, actual 1, predicted 1\n",
      "data no. 22, actual 0, predicted 0\n",
      "data no. 23, actual 0, predicted 0\n",
      "data no. 24, actual 0, predicted 0\n",
      "data no. 25, actual 0, predicted 1\n",
      "data no. 26, actual 0, predicted 0\n",
      "data no. 27, actual 0, predicted 0\n",
      "data no. 28, actual 0, predicted 0\n",
      "data no. 29, actual 0, predicted 0\n",
      "data no. 30, actual 0, predicted 0\n",
      "data no. 31, actual 0, predicted 0\n",
      "data no. 32, actual 0, predicted 0\n",
      "data no. 33, actual 0, predicted 0\n",
      "data no. 34, actual 0, predicted 0\n",
      "data no. 35, actual 0, predicted 0\n",
      "data no. 36, actual 1, predicted 1\n",
      "data no. 37, actual 1, predicted 1\n",
      "data no. 38, actual 1, predicted 1\n",
      "data no. 39, actual 1, predicted 1\n",
      "data no. 40, actual 1, predicted 1\n",
      "data no. 41, actual 1, predicted 1\n",
      "data no. 42, actual 0, predicted 0\n",
      "data no. 43, actual 1, predicted 1\n",
      "data no. 44, actual 0, predicted 0\n",
      "data no. 45, actual 1, predicted 1\n",
      "data no. 46, actual 1, predicted 1\n",
      "data no. 47, actual 1, predicted 1\n",
      "data no. 48, actual 1, predicted 1\n",
      "data no. 49, actual 0, predicted 0\n",
      "data no. 50, actual 1, predicted 1\n",
      "data no. 51, actual 1, predicted 0\n",
      "data no. 52, actual 0, predicted 0\n",
      "data no. 53, actual 0, predicted 0\n",
      "data no. 54, actual 1, predicted 1\n",
      "data no. 55, actual 0, predicted 0\n",
      "data no. 56, actual 0, predicted 0\n",
      "data no. 57, actual 0, predicted 0\n",
      "data no. 58, actual 0, predicted 0\n",
      "data no. 59, actual 1, predicted 1\n",
      "data no. 60, actual 0, predicted 0\n",
      "data no. 61, actual 0, predicted 0\n",
      "data no. 62, actual 0, predicted 0\n",
      "data no. 63, actual 1, predicted 1\n",
      "data no. 64, actual 0, predicted 0\n",
      "data no. 65, actual 1, predicted 1\n",
      "data no. 66, actual 0, predicted 0\n",
      "data no. 67, actual 1, predicted 1\n",
      "data no. 68, actual 1, predicted 1\n",
      "data no. 69, actual 0, predicted 0\n",
      "data no. 70, actual 1, predicted 1\n",
      "data no. 71, actual 0, predicted 0\n",
      "data no. 72, actual 0, predicted 0\n"
     ]
    }
   ],
   "source": [
    "y_vals_test_predict = svc.predict(x_vals_test_scaled)\n",
    "for i in range(len(y_vals_test)):\n",
    "    print('data no. %d, actual %g, predicted %g' % (i+1, y_vals_test[i], y_vals_test_predict[i])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
